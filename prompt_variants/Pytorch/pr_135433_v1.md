**Task:**
You are an automated coding agent. Fix the described bug in PyTorch’s Tensor construction path related to symbolic numbers, and add/adjust tests to prevent regressions.

**Repo Link:**
[https://github.com/pytorch/pytorch](https://github.com/pytorch/pytorch)

**Problem Statement:**
In the current implementation, when a **symbolic number** (e.g., `SymInt` or `SymFloat`) is passed into the **Tensor constructor / tensor factory**, the code may incorrectly assume that the tensor’s **dtype** matches the symbolic number’s “kind” (int vs float). This assumption is not always true (e.g., storing a `SymInt` into a float tensor), which can cause incorrect behavior.

Fix the Tensor construction/storage behavior so that symbolic numbers are stored **according to the tensor’s scalar type**, rather than assuming a fixed dtype for `SymInt`/`SymFloat`. The PR description suggests accomplishing this by wrapping the symbolic number’s guarded value in a Python object before storing it, so the correct dtype conversion rules apply.

Add or update unit tests to cover the bug and ensure correct behavior across representative dtypes and construction APIs (including both modern and legacy constructors where applicable).

**Deliverable:**
Generate a standard **git-style patch file** (unified diff, i.e., .patch file) that implements the feature and adds/updates the necessary tests.
